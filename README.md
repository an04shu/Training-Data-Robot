# ğŸ“˜ TrainingDataBot

ğŸš€ **Enterprise-Grade Data Preparation for LLMs**  
Forget toy datasets and one-off scripts. **TrainingDataBot** is your end-to-end system for:

- ğŸ“‚ **Loading** documents (PDF, TXT, URLs, etc.)  
- âš™ï¸ **Processing** them with task templates (Q&A, summarization, classification)  
- âœ… **Evaluating** quality and filtering bad examples  
- ğŸ“¦ **Exporting** curated datasets in standard formats (JSONL, CSV, etc.)  

Think of it as your **data factory** for LLM training.  

---

## ğŸŒŸ Why This Project?

Most ML repos stop at â€œI trained a model with X% accuracy.â€  
This one goes further. It mimics **real enterprise workflows**:

- Clear **entry point** (`__init__.py`) like a factory gate.  
- **Pipeline orchestration** (`TrainingDataBot`) acting as the factory manager.  
- Multiple **workers** (loaders, preprocessors, task managers, evaluators).  
- **Job tracking** with status updates (PROCESSING âœ…, FAILED âŒ).  
- **Convenience methods** (like `quick_process`) for one-liner dataset creation.  

ğŸ’¡ Itâ€™s not just a script â€” itâ€™s a **system**. The kind youâ€™d showcase in interviews or production.

---

## ğŸ—ï¸ Architecture Overview

```bash
training_data_bot/
â”œâ”€â”€ core/            # configs, logging, exceptions, data models
â”œâ”€â”€ sources/         # loaders for PDFs, web pages, text files
â”œâ”€â”€ tasks/           # task templates (Q&A, summarization, classification)
â”œâ”€â”€ preprocessing/   # text cleaning & chunking
â”œâ”€â”€ evaluation/      # quality evaluation module
â”œâ”€â”€ storage/         # dataset exporter + database manager
â””â”€â”€ bot.py           # TrainingDataBot manager (heart of the system)


ğŸ”‘ Key abstractions:
- **Documents** â†’ inputs (raw material)  
- **Jobs** â†’ processing runs (task board)  
- **Datasets** â†’ final training data (finished goods)  

---

## âš¡ Quick Start

```bash
# clone repo
git clone https://github.com/yourname/training-data-bot.git
cd training-data-bot

# install dependencies
pip install -r requirements.txt

